# Wired Article Reflection
## "Fake Pictures of People of Color Wonâ€™t Fix AI Bias" by Leo Kim
Click [here](https://www.wired.com/story/synthetic-image-media-bias-artificial-intelligence/) to read.

As artificial intelligence and machine learning gain more populartity in the tech world, its controversial shortcomings continue to be dismissed -- not because they are benign, but because they would require us to revisit a history that is so actively avoided in fear of discomfort. Although machines' capabilities continue to grow faster than most can comprehend, the foundation for these innovative features remain the same. This rotten base will likely continue to serve as the root of this revolutionary tree until it tips over from the weight of its bearings, unless its flaws are properly and directly addressed.

The very essence of instilling (pseudo)intelligence and autonomy in computers depends on training it with data compiled by generations of human activity.  Contrary to the plot of most apocalyptic robot movies, computers lack the gift of consciousness and originality. That is to say, a program may create original content, but its ability to is entirely a reflection of the education it has received. The manipulative questions and answers provided are all proposed and set by humans. A machine cannot fight against the discrimnation it propels because that is our job, as its creators, teachers, and the culprits responsible for such consequences. After all, a machine doesn't know better -- but we do.

### Darren Le's Response

The article touches on a problem often glossed over in modern AI/Machine Learning projects - the incorporation of human bias into a supposedly neutral system. As computer scientists, we are often taught to think of computers as a neutral tool that can be used to solve any problem. However, the reality is that computers are built by humans, and as such, they are inherently biased. This is not to say that computers are inherently bad, but rather that we must be aware of the biases that we are introducing into our systems. It is important to be aware of these biases so that we can mitigate them as much as possible. This is especially important in the case of AI, which is often used to make decisions that affect people's lives. For example, in the case of the article, the AI system was used to determine whether or not a person was a criminal. If the AI system is biased, then it will make decisions that are biased as well. This is a problem because it can lead to unfair treatment of people, which is something that we should try to avoid.
